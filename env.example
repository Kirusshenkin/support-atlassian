# Confluence Settings
CF_URL=https://your-tenant.atlassian.net/wiki
CF_USER=bot@company.com
CF_TOKEN=your-confluence-api-token
CF_SPACE=PROJ  # Space key to index
CF_PAGES=  # Optional: comma-separated page names, empty = all pages in space

# Retrieval Settings
RETRIEVER_K=4  # Number of chunks to retrieve
CHUNK_SIZE=800  # Maximum chunk size in characters
CHUNK_OVERLAP=120  # Overlap between chunks

# Slack Settings
SLACK_BOT_TOKEN=xoxb-your-bot-token
SLACK_APP_TOKEN=xapp-your-app-token

# LLM Settings - выберите один из провайдеров:
LLM_PROVIDER=anthropic  # Рекомендуется для лучшего качества

# === Вариант 1: Anthropic Claude (⭐ РЕКОМЕНДУЕТСЯ) ===
# Лучшее понимание контекста, отлично работает с документацией
ANTHROPIC_API_KEY=sk-ant-your-key
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# === Вариант 2: OpenAI GPT-4 ===
# Стандарт индустрии, проверенное качество
# OPENAI_API_KEY=sk-your-openai-key
# OPENAI_MODEL=gpt-4o-mini  # или gpt-4o для максимального качества

# === Вариант 3: Google Gemini (хорошая цена/качество) ===
# GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
# VERTEX_AI_PROJECT=your-project-id
# VERTEX_AI_LOCATION=us-central1
# VERTEX_AI_MODEL=gemini-1.5-pro

# === Вариант 4: Локальная модель Llama 3.1 (для конфиденциальности) ===
# MODEL_PATH=./models/llama-3.1-8b-instruct.Q4_K_M.gguf
# N_GPU_LAYERS=-1  # Использовать GPU если доступен

# === Вариант 5: Локальная модель через Ollama (проще в настройке) ===
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1:8b  # или qwen2.5:7b для русского языка

# Vector Store Settings
VECTOR_STORE_PATH=./vector_store
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
QA_SERVICE_URL=http://localhost:8000  # URL for Slack bot to connect

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
QA_SERVICE_LOG=INFO

# Reports
REPORT_DIR=./report 